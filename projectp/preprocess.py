import os
import sys
import pandas as pd

# NOTE: SELECTED_FEATURES ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å set ‡∏à‡∏≤‡∏Å pipeline ‡∏´‡∏•‡∏±‡∏Å (global)
SELECTED_FEATURES = None

def get_feature_target_columns(df: pd.DataFrame) -> tuple[list[str], str]:
    feature_cols = [c for c in df.columns if c not in ['target_event','target_direction','Date','Time','Symbol','datetime','target','pred_proba'] and df[c].dtype != 'O']
    global SELECTED_FEATURES
    if SELECTED_FEATURES:
        feature_cols = [c for c in feature_cols if c in SELECTED_FEATURES]
    if 'target_event' in df.columns:
        target_col = 'target_event'
    elif 'target_direction' in df.columns:
        target_col = 'target_direction'
    else:
        raise ValueError('‡πÑ‡∏°‡πà‡∏û‡∏ö target ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå feature engineered')
    return feature_cols, target_col

# NOTE: ensure_super_features_file ‡∏Ñ‡∏ß‡∏£ import ‡∏à‡∏≤‡∏Å feature_engineering ‡∏´‡∏£‡∏∑‡∏≠ implement stub
# ‡πÑ‡∏°‡πà import ‡∏ï‡∏£‡∏á ‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á error ‡πÉ‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô static analysis

def ensure_super_features_file() -> str:
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∑‡∏ô path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå features ‡∏´‡∏•‡∏±‡∏Å (‡πÄ‡∏ó‡∏û/robust):
    - ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠ output_default/preprocessed_super.parquet ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ
    - ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠ features_main.json ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ (feature list)
    - ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡πÉ‡∏´‡πâ‡πÅ‡∏à‡πâ‡∏á error ‡∏û‡∏£‡πâ‡∏≠‡∏° UX/‡∏™‡∏µ/‡πÄ‡∏™‡∏µ‡∏¢‡∏á/ASCII Art
    """
    import os
    import sys
    from .debug import print_logo
    try:
        from .cli import color, beep, ascii_error
    except ImportError:
        def color(x: str, c: str) -> str: return x
        def beep() -> None: pass
        def ascii_error() -> str: return ''
    parquet_path = os.path.join('output_default', 'preprocessed_super.parquet')
    json_path = 'features_main.json'
    if os.path.exists(parquet_path):
        print(color(f"[OK] ‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå features: {parquet_path}", 'green'))
        return parquet_path
    elif os.path.exists(json_path):
        print(color(f"[OK] ‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå features: {json_path}", 'green'))
        return json_path
    else:
        print_logo()
        print(color("[‚ùå] ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå features ‡∏´‡∏•‡∏±‡∏Å (preprocessed_super.parquet ‡∏´‡∏£‡∏∑‡∏≠ features_main.json)", 'red'))
        print(color("[üí°] ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏±‡∏ô‡πÇ‡∏´‡∏°‡∏î‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Preprocess) ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ü‡∏•‡πå features_main.json ‡∏Å‡πà‡∏≠‡∏ô!", 'yellow'))
        print(ascii_error())
        beep()
        sys.exit(1)

def _safe_unique(val) -> list[str]:
    # Helper: convert unique() result to list, fallback to str if error
    try:
        return list(val.unique())
    except Exception:
        return [str(x) for x in val]

def run_preprocess():
    """Preprocess pipeline: ‡πÇ‡∏´‡∏•‡∏î feature engineered + target ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥, ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å feature/target ‡πÉ‡∏´‡∏°‡πà, ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å preprocessed_super.parquet"""
    fe_super_path = ensure_super_features_file()
    df = pd.read_parquet(fe_super_path)
    feature_cols, target_col = get_feature_target_columns(df)
    print(f'‡πÉ‡∏ä‡πâ feature: {feature_cols}')
    print(f'‡πÉ‡∏ä‡πâ target: {target_col}')
    df_out = df[feature_cols + [target_col]].dropna().reset_index(drop=True)
    # ‡πÑ‡∏°‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'target' ‡∏ã‡πâ‡∏≥‡∏ñ‡πâ‡∏≤‡∏°‡∏µ target ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß
    if 'target' not in df_out.columns:
        df_out['target'] = df_out[target_col]
    if 'pred_proba' not in df_out.columns:
        df_out['pred_proba'] = 0.5  # default dummy value
    print(f'[DEBUG][preprocess] df_out shape: {df_out.shape}')
    print(f'[DEBUG][preprocess] target unique: {_safe_unique(df_out[target_col])}')
    for col in feature_cols:
        print(f'[DEBUG][preprocess] {col} unique: {_safe_unique(df_out[col])[:5]}')
    if len(_safe_unique(df_out[target_col])) == 1:
        print(f"[STOP][preprocess] Target ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß: {_safe_unique(df_out[target_col])} ‡∏´‡∏¢‡∏∏‡∏î pipeline")
        sys.exit(1)
    out_path = os.path.join('output_default', 'preprocessed_super.parquet')
    df_out.to_parquet(out_path)
    print(f'‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå preprocessed_super.parquet ‡∏î‡πâ‡∏ß‡∏¢ feature/target ‡πÉ‡∏´‡∏°‡πà ({target_col})')
